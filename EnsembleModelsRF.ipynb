{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to explore the efficacy of *ensemble models* on a classification problem based on the `make_circles` dataset available in SKLearn.\n",
    "\n",
    "Inside, we will create examples of some of the concepts we discussed in the lecture and plot the outputs.\n",
    "\n",
    "Specifically we will explore:\n",
    "  * Hard voting aggregation of varied algorithms\n",
    "  * Soft voting aggregation of varied algorithms\n",
    "  * Stacking\n",
    "  * Bagging\n",
    "  * Boosting\n",
    "\n",
    "Please note that the base machine learning algorithms in this notebook have been throttled down significantly in order to better showcase the improvement that ensemble models can provide. In reality, this dataset is sufficiently simple that even trivial hyperparameter tuning can result in significantly better prediction accuracies than you see here!\n",
    "\n",
    "I have tried to be as fair as possible (e.g. comparing a rubbish decision tree with a random forest composed of rubbish decision trees), but some of the most egregious things you can expect to see here:\n",
    "  * Terrible train/test splits\n",
    "  * Horrible choices of algorithms (LogReg and LinearSVM for circles?!)\n",
    "  * Extremely shallow trees (Making a single decision point for 2D data necessarily leads to a straight line -- not a great way of identifying circles)\n",
    "  \n",
    "Hopefully, despite the handicaps our poor models are subjected to, the main points of why ensemble models are powerful will be apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the packages we need.\n",
    "\n",
    "I also turn off warnings here -- I'm running an old version of SKLearn here (0.20.3) and it's very vocal about default behaviours and futureproofing your code. They're just warnings so if you see them in your own code, you don't have to worry about them, I just found them distracting so turned them off.\n",
    "\n",
    "The final line is a bit of Jupyter \"cell magic\" to plot the figures in-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import sklearn.calibration\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.svm\n",
    "import sklearn.tree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function sets up the main plotting used in this notebook to visualise the full dataset we are exploring, as well as any decision boundaries calculated by each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circles(coordinates, circle_id, title=None, decision_region=None):\n",
    "    matplotlib.pyplot.figure(figsize=(10, 10), facecolor=\"white\")\n",
    "    \n",
    "    # Plot main data\n",
    "    matplotlib.pyplot.scatter(coordinates[circle_id == 0][:, 0], coordinates[circle_id == 0][:, 1], c=\"r\", label=\"circle 1\")\n",
    "    matplotlib.pyplot.scatter(coordinates[circle_id == 1][:, 0], coordinates[circle_id == 1][:, 1], c=\"b\", label=\"circle 2\")\n",
    "    \n",
    "    # Plot decision regions\n",
    "    if decision_region is not None:\n",
    "        (xx, yy, Z) = decision_region\n",
    "        matplotlib.pyplot.contourf(xx, yy, Z, cmap=matplotlib.pyplot.cm.seismic_r, alpha=0.4)\n",
    "        \n",
    "    \n",
    "    matplotlib.pyplot.xlabel(\"X Coordinate (Arb. U.)\", fontsize=28)\n",
    "    matplotlib.pyplot.ylabel(\"Y Coordinate (Arb. U.)\", fontsize=28)\n",
    "    matplotlib.pyplot.legend(fontsize=16)\n",
    "    if title is not None:\n",
    "        matplotlib.pyplot.title(title, fontsize=18)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make and visualise our input data!\n",
    "\n",
    "In this case we'll be generating a set of 1000 datapoints that are classified into an inner circle and an outer annulus with double the radius.\n",
    "\n",
    "We also add in some Gaussian noise to the coordinates to make it a little less clean, with a standard deviation of 0.3 arbitrary units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates, circle_id = sklearn.datasets.make_circles(n_samples=1000, noise=0.3, factor=0.5, random_state=42)\n",
    "print(\"Coordinates {} = {}\".format(coordinates.shape, coordinates))\n",
    "print(\"Circle {} = {}\".format(circle_id.shape, circle_id))\n",
    "plot_circles(coordinates, circle_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data. As I mentioned before, I'm going to hamstring my models by only providing them 10% of the data to train on. This will make them all rubbish to show you how even the weakest predictors can still provide good results when combined correctly in an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(coordinates, circle_id, train_size=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Hard and Soft Voting Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, we will use 3 different models, none of which are particularly good at solving this problem:\n",
    "  * LR -- A Logistic Regression model\n",
    "  * DT -- A Decision Tree\n",
    "  * SVM -- A Linear Support Vector Classifier\n",
    "  \n",
    "Rather than just using `sklearn.svm.LinearSVC`, we nestle it within a `sklearn.calibration.CalibratedClassifierCV`. This is because `LinearSVC` doesn't output the prediction probabilities by default. Wrapping it allows us to include it in our soft-voting ensemble, which requires some measure of confidence in the classification in order to judge how much (or little) to weight the SVM's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = sklearn.linear_model.LogisticRegression(random_state=42)\n",
    "DT = sklearn.tree.DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "SVM = sklearn.calibration.CalibratedClassifierCV(sklearn.svm.LinearSVC(random_state=42))\n",
    "\n",
    "voting_hard = sklearn.ensemble.VotingClassifier(\n",
    "    estimators=[(\"LR\", LR), (\"DT\", DT), (\"SVM\", SVM)],# (\"KN\", KN)],\n",
    "    voting=\"hard\"\n",
    ")\n",
    "\n",
    "voting_soft = sklearn.ensemble.VotingClassifier(\n",
    "    estimators=[(\"LR\", LR), (\"DT\", DT), (\"SVM\", SVM)],# (\"KN\", KN)],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LR,\n",
    "    \"Decision Tree\": DT,\n",
    "    \"Linear Support Vector Machine\": SVM,\n",
    "    \"Voting (Hard)\": voting_hard,\n",
    "    \"Voting (Soft)\": voting_soft,\n",
    "}\n",
    "\n",
    "accuracy = []\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy.append(sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "    # Obtain the decision regions for plotting\n",
    "    x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "    y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "    xx, yy = numpy.meshgrid(\n",
    "        numpy.arange(x_min, x_max, 0.02),\n",
    "        numpy.arange(y_min, y_max, 0.02)\n",
    "    )\n",
    "    Z = model.predict(numpy.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    plot_circles(\n",
    "        coordinates,\n",
    "        circle_id,\n",
    "        title=\"Predictions from {} (Accuracy = {:.4f})\".format(model_name, accuracy[-1]),\n",
    "        decision_region=(xx, yy, Z)\n",
    "    )\n",
    "\n",
    "print(\"---=== ACCURACY SUMMARY ===---\")\n",
    "for model_index, model_name in enumerate(models.keys()):\n",
    "    print(model_name, \"{:.4f}\".format(accuracy[model_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have pretty varied results from each classifier. The decision tree did pretty well compared to the other two.\n",
    "\n",
    "Look at the decision surfaces for the hard and soft voting classifiers though. With the hard voting, you can clearly see the decision surface shapes corresponding to the LR at the top, the DT on the right and the SVM on the left. Each quadrant is dominated by a single model. It's picked the model that did best in each quadrant, but has not in any way mixed the decision surfaces to get a more accurate prediction.\n",
    "\n",
    "The soft classifier on the other hand has produced a pretty interesting decision surface. It's easy to pick out the shape of the DT surface from the right hand side of the result, but on the left there are components of the surface that are not directly present in any of the other surfaces.\n",
    "\n",
    "It is this ability to interpolate a new decision surface that can boost the soft-classifier's accuracy.\n",
    "\n",
    "For this example neither of the ensemble models outperformed the decision tree, but there was a signficant improvement from using soft-voting to aggregate the predictions than hard-voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The `sklearn.ensemble.StackingClassifier` function can be used here instead of performing the stacking manually as below, but I wanted to show you the process.\n",
    "\n",
    "In order to employ stacking, we need to first split our training data into two subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_X1, subset_X2, subset_y1, subset_y2 = sklearn.model_selection.train_test_split(X_train, y_train, train_size=80, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the models we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR1 = sklearn.linear_model.LogisticRegression(random_state=42)\n",
    "DT1 = sklearn.tree.DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "SVM1 = sklearn.svm.LinearSVC(random_state=42)\n",
    "\n",
    "layer_1 = {\n",
    "    \"Logistic Regression\": LR1,\n",
    "    \"Decision Tree\": DT1,\n",
    "    \"Linear Support Vector Machine\": SVM1,\n",
    "}\n",
    "\n",
    "blender = sklearn.linear_model.LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit each model to the first subset, and generate predictions for the second subset. We form a `predictions_array`, and will build the training data for the blender from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_array_train = []\n",
    "accuracies = []\n",
    "for model_name, model in layer_1.items():\n",
    "    model.fit(subset_X1, subset_y1)\n",
    "    predictions_array_train.append(model.predict(subset_X2))\n",
    "    accuracies.append(sklearn.metrics.accuracy_score(subset_y2, predictions_array_train[-1]))\n",
    "\n",
    "blender_input = numpy.array(list(zip(*predictions_array_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the blender (a Logitistic Regression Model) to the input data, knowing it should fit to `subset_y2` defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender.fit(blender_input, subset_y2)\n",
    "\n",
    "predictions_array_test = []\n",
    "for model_name, model in layer_1.items():\n",
    "    predictions_array_test.append(model.predict(X_test))\n",
    "blender_test_inputs = numpy.array(list(zip(*predictions_array_test)))\n",
    "    \n",
    "predictions = blender.predict(blender_test_inputs)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "\n",
    "for index, (feature, coeff) in enumerate(list(zip(list(layer_1.keys()) + [\"INTERCEPT\"], list(blender.coef_[0]) + list(blender.intercept_)))):\n",
    "    try:\n",
    "        print(\"Coefficient for {} = {:.4f} (Accuracy Metric = {:.4f})\".format(feature, coeff, accuracies[index]))\n",
    "    except IndexError:\n",
    "        print(\"Coefficient for {} = {:.4f}\".format(feature, coeff))\n",
    "        \n",
    "    \n",
    "print(\"\\nStacked Ensemble Accuracy = {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By training the Blender on the second layer, the Decision tree is weighted more highly than the other two models. However, all models actively contribute to the final ensemble accuracy, and so the ensemble performs better than any of the consituent models themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A classifier consisting of multiple Decision Tree estimators with bagging of training data is effectively the same as a Random Forest. In the below code, we could use the useful SKLearn helper class `RandomForestClassifier` instead.\n",
    "\n",
    "Let's take a look at an example of Bagging using an ensemble of 200 decision trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = sklearn.tree.DecisionTreeClassifier(random_state=42, max_depth=1)\n",
    "model_forest = sklearn.ensemble.BaggingClassifier(\n",
    "    sklearn.tree.DecisionTreeClassifier(random_state=424, max_depth=1),\n",
    "    n_estimators=50,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for model in (model_tree, model_forest):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy.append(sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "    \n",
    "    # Obtain the decision regions for plotting\n",
    "    x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "    y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "    xx, yy = numpy.meshgrid(\n",
    "        numpy.arange(x_min, x_max, 0.02),\n",
    "        numpy.arange(y_min, y_max, 0.02)\n",
    "    )\n",
    "    Z = model.predict(numpy.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    plot_circles(\n",
    "        coordinates,\n",
    "        circle_id,\n",
    "        title=\"Predictions from {} (Accuracy = {:.4f})\".format(model.__class__.__name__, accuracy[-1]),\n",
    "        decision_region=(xx, yy, Z)\n",
    "    )\n",
    "\n",
    "print(\"The Random Forest is a {:.2f}% improvement over the Decision Tree!\".format((100 * (accuracy[1] - accuracy[0]) / accuracy[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that each decision tree makes a single decision and so can divide the data plane into two decision surfaces, an ensemble of 50 trees can make multiple cuts, increasing the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of just bagging, we can also do some Boosting using the AdaBoost algorithm we discussed in the presentation.\n",
    "\n",
    "If we use the same terrible trees, but this time instead of restricting their training data (or feature set, although that's kind of a moot point when there are only 2 input features), and use the same number of estimators for our Forest (50), can we obtain an improvement by training them sequentially to address the shortcomings of the previous predictor rather than in parallel like above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ada = sklearn.ensemble.AdaBoostClassifier(\n",
    "    sklearn.tree.DecisionTreeClassifier(random_state=4242, max_depth=1),\n",
    "    n_estimators=50,\n",
    "    algorithm=\"SAMME.R\",\n",
    "    learning_rate=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for model in (model_tree, model_ada):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy.append(sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "    \n",
    "    # Obtain the decision regions for plotting\n",
    "    x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "    y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "    xx, yy = numpy.meshgrid(\n",
    "        numpy.arange(x_min, x_max, 0.02),\n",
    "        numpy.arange(y_min, y_max, 0.02)\n",
    "    )\n",
    "    Z = model.predict(numpy.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    plot_circles(\n",
    "        coordinates,\n",
    "        circle_id,\n",
    "        title=\"Predictions from {} (Accuracy = {:.4f})\".format(model.__class__.__name__, accuracy[-1]),\n",
    "        decision_region=(xx, yy, Z)\n",
    "    )\n",
    "\n",
    "print(\"The Ada Boosted Forest is a {:.2f}% improvement over the Decision Tree!\".format((100 * (accuracy[1] - accuracy[0]) / accuracy[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance improvement is huge! Before, most of the 50 trees ended up being the same because they could only make one decision on one of the two input features, and so most of the trees actually looked idential. This time, by weighting the training instances for each predictor, the trees end up being much more diverse, which allows for significantly better predictive capability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
